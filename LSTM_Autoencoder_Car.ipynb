{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Autoencoder_Car.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOomONFSCbLDrAk6e1yTSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelMendozaG/CANproject/blob/6_features/LSTM_Autoencoder_Car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nstTsL_j_1U_"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "DATA_SPLIT_PCT = 0.2\n",
        "SEED = 123\n",
        "max_size = 100\n",
        "n_features = 6\n",
        "lookback = max_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCg9AF4zASHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558f35fc-19a5-4f2a-d107-c3e5b06de0d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "model_dir = '/content/gdrive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHBnIT5LAjPI"
      },
      "source": [
        "car_model = \"Colab Notebooks/Car\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDDQ99N5B9PS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28763462-793e-479c-8dff-c27175f8f734"
      },
      "source": [
        "model_dir + car_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/Car'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdCGfEXRAxyn"
      },
      "source": [
        "data = np.load(model_dir + car_model + '/recorrido.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfBLLv9LMts8"
      },
      "source": [
        "def temporalize(X, y, lookback):\n",
        "    output_X = []\n",
        "    output_y = []\n",
        "    for i in range(len(X)-lookback-1):\n",
        "        t = []\n",
        "        for j in range(0,lookback):\n",
        "            # Gather past records upto the lookback period\n",
        "            t.append(X[[(i+j)], :])\n",
        "        output_X.append(t)\n",
        "        output_y.append(y[i+lookback])\n",
        "    return output_X, output_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp7sfbZz4SxV"
      },
      "source": [
        "def flatten(X):\n",
        "    '''\n",
        "    Flatten a 3D array.\n",
        "    \n",
        "    Input\n",
        "    X            A 3D array for lstm, where the array is sample x timesteps x features.\n",
        "    \n",
        "    Output\n",
        "    flattened_X  A 2D array, sample x features.\n",
        "    '''\n",
        "    flattened_X = np.empty((X.shape[0], X.shape[2]) )  # sample x features array.\n",
        "    for i in range(X.shape[0]):\n",
        "      flattened_X[i] = X[i, (X.shape[1]-1), :]\n",
        "    return(flattened_X)\n",
        "\n",
        "def scale(X, scaler):\n",
        "    '''\n",
        "    Scale 3D array.\n",
        "\n",
        "    Inputs\n",
        "    X            A 3D array for lstm, where the array is sample x timesteps x features.\n",
        "    scaler       A scaler object, e.g., sklearn.preprocessing.StandardScaler, sklearn.preprocessing.normalize\n",
        "    \n",
        "    Output\n",
        "    X            Scaled 3D array.\n",
        "    '''\n",
        "    for i in range(X.shape[0]):\n",
        "        X[i, :, :] = scaler.transform(X[i, :, :])\n",
        "        \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0omkd8-SD3I3"
      },
      "source": [
        "X_train, X_test = train_test_split(np.array(data), test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
        "X_train, X_validation = train_test_split(X_train, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
        "X_train_original_shape = X_train.shape\n",
        "X_test_original_shape = X_test.shape\n",
        "X_validation_original_shape = X_validation.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdB0zT1cBNvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1543a525-cc64-48b3-f5a7-f8c9dc85f8b3"
      },
      "source": [
        "X_train_reshape = X_train.reshape(X_train.shape[0], lookback, n_features)\n",
        "X_train_float = np.empty((X_train_reshape.shape[0], X_train_reshape.shape[1], X_train_reshape.shape[2]))\n",
        "X_train_float = np.array(X_train_reshape, dtype= np.float64)\n",
        "\n",
        "X_test_reshape = X_test.reshape(X_test.shape[0], lookback, n_features)\n",
        "X_test_float = np.empty((X_test_reshape.shape[0], X_test_reshape.shape[1], X_test_reshape.shape[2]))\n",
        "X_test_float = np.array(X_test_reshape, dtype= np.float64)\n",
        "\n",
        "X_validation_reshape = X_validation.reshape(X_validation.shape[0], lookback, n_features)\n",
        "X_validation_float = np.empty((X_validation_reshape.shape[0], X_validation_reshape.shape[1], X_validation_reshape.shape[2]))\n",
        "X_validation_float = np.array(X_validation_reshape, dtype= np.float64)\n",
        "\n",
        "print (X_train_reshape.shape)\n",
        "print (X_test_reshape.shape)\n",
        "print (X_validation_reshape.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24788, 100, 6)\n",
            "(7747, 100, 6)\n",
            "(6198, 100, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkrlpyqKLX9M"
      },
      "source": [
        "X_train_split = flatten(X_train_reshape)\n",
        "X_train_array = np.array(np.hsplit( X_train_split, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWthUTniAN_9"
      },
      "source": [
        "X_array_float = np.empty((X_train_reshape.shape[0], X_train_reshape.shape[1], X_train_reshape.shape[2]))\n",
        "X_array_float = np.array(X_train_reshape, dtype= np.float64)\n",
        "\n",
        "# define min max scalers for each message\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "scaler3 = MinMaxScaler()\n",
        "scaler4 = MinMaxScaler()\n",
        "scaler5 = MinMaxScaler()\n",
        "scaler6 = MinMaxScaler()\n",
        "\n",
        "X_array_float[:,:,0] = scaler1.fit_transform(X_train_reshape[:,:,0])\n",
        "X_array_float[:,:,1] = scaler2.fit_transform(X_train_reshape[:,:,1])\n",
        "X_array_float[:,:,2] = scaler3.fit_transform(X_train_reshape[:,:,2])\n",
        "X_array_float[:,:,3] = scaler4.fit_transform(X_train_reshape[:,:,3])\n",
        "X_array_float[:,:,4] = scaler5.fit_transform(X_train_reshape[:,:,4])\n",
        "X_array_float[:,:,5] = scaler6.fit_transform(X_train_reshape[:,:,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HNubvBCE9xI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77dc51c-7070-4d34-8bbd-484058aee5d1"
      },
      "source": [
        "#Train statistics\n",
        "print (\"Msg 1\")\n",
        "print(X_train_float[:,:,5])\n",
        "print (X_train_float.min(), X_train_float.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Msg 1\n",
            "[[2.24599880e-15 2.43720388e-15 2.64603154e-15 ... 2.43720388e-15\n",
            "  2.64603154e-15 2.83018758e-15]\n",
            " [2.77777778e-02 2.77777778e-02 2.77777778e-02 ... 4.36507937e-02\n",
            "  4.16666667e-02 4.16666667e-02]\n",
            " [1.64859308e-15 1.99487693e-15 2.24599880e-15 ... 1.99487693e-15\n",
            "  2.24599880e-15 2.43720388e-15]\n",
            " ...\n",
            " [2.24599880e-15 2.43720388e-15 2.64603154e-15 ... 2.43720388e-15\n",
            "  2.64603154e-15 2.83018758e-15]\n",
            " [2.24599880e-15 2.43720388e-15 2.64603154e-15 ... 2.43720388e-15\n",
            "  2.64603154e-15 2.83018758e-15]\n",
            " [4.18650794e-01 4.20634921e-01 4.20634921e-01 ... 5.03968254e-01\n",
            "  5.05952381e-01 5.07936508e-01]]\n",
            "0.0 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qOaxmqPFZyA"
      },
      "source": [
        "#transform test and validation with minmax statistics\n",
        "X_test_array_1 = scaler1.transform(X_test_array[0])\n",
        "X_test_array_2 = scaler2.transform(X_test_array[1])\n",
        "X_test_array_3 = scaler3.transform(X_test_array[2])\n",
        "X_test_array_4 = scaler4.transform(X_test_array[3])\n",
        "X_test_array_5 = scaler5.transform(X_test_array[4])\n",
        "X_test_array_6 = scaler6.transform(X_test_array[5])\n",
        "\n",
        "X_validation_array_1 = scaler1.transform(X_validation_array[0])\n",
        "X_validation_array_2 = scaler2.transform(X_validation_array[1])\n",
        "X_validation_array_3 = scaler3.transform(X_validation_array[2])\n",
        "X_validation_array_4 = scaler4.transform(X_validation_array[3])\n",
        "X_validation_array_5 = scaler5.transform(X_validation_array[4])\n",
        "X_validation_array_6 = scaler6.transform(X_validation_array[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkiEBgGptYV3"
      },
      "source": [
        "a = scaler1.transform(X_validation_reshape[:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY7CPt7GGNRn",
        "outputId": "cdbce2af-3b76-49c0-f47a-21f6235b1b9e"
      },
      "source": [
        "#Test statistics\n",
        "print (\"Msg 1\")\n",
        "print(X_test_float[:,:,5])\n",
        "print (X_test_float.min(), X_test_float.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Msg 1\n",
            "[[9.86111111e-01 9.86111111e-01 9.86111111e-01 ... 9.94047619e-01\n",
            "  9.94047619e-01 9.96031746e-01]\n",
            " [2.43720388e-15 2.64603154e-15 2.83018758e-15 ... 2.64603154e-15\n",
            "  2.83018758e-15 3.04606428e-15]\n",
            " [2.43720388e-15 2.64603154e-15 2.83018758e-15 ... 2.64603154e-15\n",
            "  2.83018758e-15 3.04606428e-15]\n",
            " ...\n",
            " [5.19841270e-01 5.19841270e-01 5.17857143e-01 ... 4.70238095e-01\n",
            "  4.68253968e-01 4.68253968e-01]\n",
            " [3.53068544e-15 0.00000000e+00 2.37023804e-16 ... 0.00000000e+00\n",
            "  2.37023804e-16 4.84621162e-16]\n",
            " [0.00000000e+00 2.37023804e-16 4.84621162e-16 ... 2.37023804e-16\n",
            "  4.84621162e-16 7.07546896e-16]]\n",
            "-3.4395526871122684e-07 1.1578943508013504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-wGc29HqBYD",
        "outputId": "a6ccff62-761f-475d-e557-6954da4e9ff1"
      },
      "source": [
        "#Validation statistics\n",
        "print (\"Msg 1\")\n",
        "print (a)\n",
        "print (a.min(), a.max())\n",
        "print(X_validation_float[:,:,0])\n",
        "print (X_validation_float.min(), X_validation_float.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Msg 1\n",
            "[[0.59090835 0.59090826 0.59090826 ... 0.59090826 0.68420838 0.6842081 ]\n",
            " [0.59091125 0.59091125 0.59091125 ... 0.59091238 0.68421315 0.68421266]\n",
            " [0.59090852 0.59090852 0.59090852 ... 0.59090818 0.68420828 0.6842078 ]\n",
            " ...\n",
            " [0.59090878 0.59090861 0.59090861 ... 0.5909074  0.68420788 0.68420739]\n",
            " [0.59090887 0.59090878 0.59090878 ... 0.59090835 0.68420828 0.6842078 ]\n",
            " [0.5909087  0.5909087  0.59090878 ... 0.59090818 0.68420908 0.6842086 ]]\n",
            "-3.4395526871122684e-07 1.1578919099500897\n",
            "[[0.59090835 0.59090826 0.59090826 ... 0.59090826 0.68420838 0.6842081 ]\n",
            " [0.59091125 0.59091125 0.59091125 ... 0.59091238 0.68421315 0.68421266]\n",
            " [0.59090852 0.59090852 0.59090852 ... 0.59090818 0.68420828 0.6842078 ]\n",
            " ...\n",
            " [0.59090878 0.59090861 0.59090861 ... 0.5909074  0.68420788 0.68420739]\n",
            " [0.59090887 0.59090878 0.59090878 ... 0.59090835 0.68420828 0.6842078 ]\n",
            " [0.5909087  0.5909087  0.59090878 ... 0.59090818 0.68420908 0.6842086 ]]\n",
            "-3.4395526871122684e-07 1.1578919099500897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKkVl-xPHMrB",
        "outputId": "b3f11d94-b676-4899-dc7c-83539c4191bd"
      },
      "source": [
        "#Validation statistics\n",
        "print (\"Msg 1\")\n",
        "print(X_validation_array_1)\n",
        "print (X_validation_array_1.min(), X_validation_array_1.max())\n",
        "print (\"Msg 2\")\n",
        "print(X_validation_array_2)\n",
        "print (X_validation_array_2.min(), X_validation_array_2.max())\n",
        "print (\"Msg 3\")\n",
        "print(X_validation_array_3)\n",
        "print (X_validation_array_3.min(), X_validation_array_3.max())\n",
        "print (\"Msg 4\")\n",
        "print(X_validation_array_4)\n",
        "print (X_validation_array_4.min(), X_validation_array_4.max())\n",
        "print (\"Msg 5\")\n",
        "print(X_validation_array_5)\n",
        "print (X_validation_array_5.min(), X_validation_array_5.max())\n",
        "print (\"Msg 6\")\n",
        "print(X_validation_array_6)\n",
        "print (X_validation_array_6.min(), X_validation_array_6.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Msg 1\n",
            "[[0.6842081 ]\n",
            " [0.68421266]\n",
            " [0.6842078 ]\n",
            " ...\n",
            " [0.68420739]\n",
            " [0.6842078 ]\n",
            " [0.6842086 ]]\n",
            "0.0 1.1578919099500897\n",
            "Msg 2\n",
            "[[0.23268554]\n",
            " [0.74515159]\n",
            " [0.21329512]\n",
            " ...\n",
            " [0.14404437]\n",
            " [0.21329512]\n",
            " [0.33517932]]\n",
            "0.0 0.9778393276875939\n",
            "Msg 3\n",
            "[[0.        ]\n",
            " [0.30830079]\n",
            " [0.        ]\n",
            " ...\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]]\n",
            "0.0 1.0000002411574607\n",
            "Msg 4\n",
            "[[4.52481553e-02]\n",
            " [3.07368804e-01]\n",
            " [4.97416650e-01]\n",
            " ...\n",
            " [4.52634743e-02]\n",
            " [4.97416650e-01]\n",
            " [2.33750375e-10]]\n",
            "0.0 0.9999220173685515\n",
            "Msg 5\n",
            "[[0.8438072 ]\n",
            " [0.74996949]\n",
            " [0.8438072 ]\n",
            " ...\n",
            " [0.75009152]\n",
            " [0.84368517]\n",
            " [0.84368517]]\n",
            "0.0 0.9998779743746187\n",
            "Msg 6\n",
            "[[1.64859308e-15]\n",
            " [3.07539683e-01]\n",
            " [7.07546896e-16]\n",
            " ...\n",
            " [1.64859308e-15]\n",
            " [1.40452024e-15]\n",
            " [2.43720388e-15]]\n",
            "0.0 0.9999999999999984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-1eByonECw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcceb199-1d06-4b2b-acb8-6f1562434915"
      },
      "source": [
        "'''\n",
        "print(X_test.shape)\n",
        "#X_test_1 = Scaler(X_test, mm_scaler)\n",
        "X_test = mm_scaler.transform(X_test.reshape(X_test.shape[0]*X_test.shape[1], 1))\n",
        "X_validation = mm_scaler.transform(X_validation.reshape(X_validation.shape[0]*X_validation.shape[1], 1))\n",
        "print (X_test.shape)\n",
        "print (X_validation.shape)\n",
        "X_test = X_test.reshape(X_test_original_shape[0], max_size, 1)\n",
        "X_validation = X_validation.reshape(X_validation_original_shape[0], max_size, 1)\n",
        "print (X_test)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7747, 100, 1)\n",
            "(774700, 1)\n",
            "(619800, 1)\n",
            "[[[0.59090844]\n",
            "  [0.5909087 ]\n",
            "  [0.5909087 ]\n",
            "  ...\n",
            "  [0.59090835]\n",
            "  [0.59090826]\n",
            "  [0.59090826]]\n",
            "\n",
            " [[0.59091117]\n",
            "  [0.59091117]\n",
            "  [0.59091117]\n",
            "  ...\n",
            "  [0.59091151]\n",
            "  [0.5909116 ]\n",
            "  [0.5909116 ]]\n",
            "\n",
            " [[0.59091052]\n",
            "  [0.59091052]\n",
            "  [0.59091052]\n",
            "  ...\n",
            "  [0.59091008]\n",
            "  [0.59091008]\n",
            "  [0.59091008]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.59090826]\n",
            "  [0.59090826]\n",
            "  [0.59090826]\n",
            "  ...\n",
            "  [0.59090818]\n",
            "  [0.59090818]\n",
            "  [0.59090818]]\n",
            "\n",
            " [[0.59090826]\n",
            "  [0.59090826]\n",
            "  [0.59090826]\n",
            "  ...\n",
            "  [0.59090826]\n",
            "  [0.59090826]\n",
            "  [0.59090826]]\n",
            "\n",
            " [[0.59090861]\n",
            "  [0.59090878]\n",
            "  [0.59090887]\n",
            "  ...\n",
            "  [0.59090835]\n",
            "  [0.59090835]\n",
            "  [0.59090835]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C-HTxqrK9an"
      },
      "source": [
        "X_train = X_train.reshape(X_train_original_shape[0], max_size, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wUWibR3nNQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8153342e-cfb2-47c2-e723-1d47f54d4f0d"
      },
      "source": [
        "timesteps = X_train.shape[1]\n",
        "n_features = X_train.shape[2]\n",
        "lr = 0.0001\n",
        "print(timesteps)\n",
        "print(n_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCvF3t0BmuE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e28b9cf-96b8-4628-e7c3-fa38f056588e"
      },
      "source": [
        "lstm_autoencoder = Sequential()\n",
        "# Encoder\n",
        "lstm_autoencoder.add(LSTM(32, activation='relu', input_shape=(timesteps, n_features), return_sequences=True))\n",
        "lstm_autoencoder.add(LSTM(16, activation='relu', return_sequences=False))\n",
        "lstm_autoencoder.add(RepeatVector(timesteps))\n",
        "# Decoder\n",
        "lstm_autoencoder.add(LSTM(16, activation='relu', return_sequences=True))\n",
        "lstm_autoencoder.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "lstm_autoencoder.add(TimeDistributed(Dense(n_features)))\n",
        "\n",
        "lstm_autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 32)           4352      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 16)                3136      \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 100, 16)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100, 16)           2112      \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100, 32)           6272      \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 100, 1)            33        \n",
            "=================================================================\n",
            "Total params: 15,905\n",
            "Trainable params: 15,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edeFNYo2nCeI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "35ac54c7-2205-4c2c-f051-bfbbf50c17c0"
      },
      "source": [
        "adam = optimizers.Adam(lr)\n",
        "lstm_autoencoder.compile(loss='mse', optimizer=adam)\n",
        "# fit model\n",
        "lstm_autoencoder_history = lstm_autoencoder.fit(X_train, X_train, validation_data=(X_validation, X_validation),\n",
        "                                                verbose=1, epochs=300, batch_size=100).history\n",
        "yhat = lstm_autoencoder.predict(X_train, verbose=0)\n",
        "\n",
        "plt.plot(lstm_autoencoder_history['loss'], linewidth=2, label='Train')\n",
        "plt.plot(lstm_autoencoder_history['val_loss'], linewidth=2, label='Valid')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "248/248 [==============================] - 143s 578ms/step - loss: 0.1311 - val_loss: 0.0216\n",
            "Epoch 2/300\n",
            "248/248 [==============================] - 137s 552ms/step - loss: 0.0150 - val_loss: 0.0085\n",
            "Epoch 3/300\n",
            "248/248 [==============================] - 133s 536ms/step - loss: 0.0083 - val_loss: 0.0076\n",
            "Epoch 4/300\n",
            "248/248 [==============================] - 129s 520ms/step - loss: 0.0050 - val_loss: 5.7844e-04\n",
            "Epoch 5/300\n",
            " 84/248 [=========>....................] - ETA: 1:21 - loss: 4.4112e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f75fba1c5008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m lstm_autoencoder_history = lstm_autoencoder.fit(X_train, X_train, validation_data=(X_validation, X_validation),\n\u001b[0;32m----> 5\u001b[0;31m                                                 verbose=1, epochs=300, batch_size=100).history\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyp24qz3ppNy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}